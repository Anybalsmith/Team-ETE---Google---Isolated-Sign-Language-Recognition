{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":46105,"databundleVersionId":5087314,"sourceType":"competition"},{"sourceId":8558594,"sourceType":"datasetVersion","datasetId":5115292,"isSourceIdPinned":false},{"sourceId":8723434,"sourceType":"datasetVersion","datasetId":5234941},{"sourceId":8739694,"sourceType":"datasetVersion","datasetId":5247040},{"sourceId":65991,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":55035},{"sourceId":65992,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":55036},{"sourceId":66329,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":55322},{"sourceId":66330,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":55323},{"sourceId":66777,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":55675}],"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [markdown]\n# ## **Sign Language Recognition**\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:25:30.366571Z\",\"iopub.execute_input\":\"2024-07-11T11:25:30.367233Z\",\"iopub.status.idle\":\"2024-07-11T11:25:30.375071Z\",\"shell.execute_reply.started\":\"2024-07-11T11:25:30.367188Z\",\"shell.execute_reply\":\"2024-07-11T11:25:30.373431Z\"}}\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport json\nimport pickle\n\nimport os\nimport random\nimport matplotlib.pyplot as plt\n\nfrom IPython.display import display, clear_output, update_display\nimport time\n\n# %% [markdown]\n# ### Required files:\n# - competition dataset:\n#     - *train_landmark_files*\n#     - *train.csv*\n#     - *sign_to_prediction_index_map.json*\n#  \n# - personal dataset:\n#     - *preprocess_dataset.pkl*\n#    \n# - personal data:\n#     - *cm_test.pt*\n#     - *class_report.csv*\n# - models:\n#     - *pointnet_transformer_model1_60.pth*\n# \n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:25:30.377190Z\",\"iopub.execute_input\":\"2024-07-11T11:25:30.377888Z\",\"iopub.status.idle\":\"2024-07-11T11:25:30.629645Z\",\"shell.execute_reply.started\":\"2024-07-11T11:25:30.377850Z\",\"shell.execute_reply\":\"2024-07-11T11:25:30.628529Z\"}}\nCOMPETITION_PATH = '/kaggle/input/asl-signs/'\nPROCESS_DATASET_PATH = \"/kaggle/input/preprocess-dataset/preprocess_dataset.pkl\"\ndataset_path = '/kaggle/input/asl-signs/train_landmark_files'\nuser_ids = os.listdir('/kaggle/input/asl-signs/train_landmark_files')\n\n# lips idx\nLIPS_IDXS0 = np.array([\n        61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n        291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n        78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n        95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n    ])\n\n# left hand, by taking account face from 0 to 468\nLEFT_HAND_IDXS0 = np.arange(468,489)\nRIGHT_HAND_IDXS0 = np.arange(522,543)\nLEFT_POSE_IDXS0 = np.array([502, 504, 506, 508, 510])\nRIGHT_POSE_IDXS0 = np.array([503, 505, 507, 509, 511])\n\nREDUCED_LANDMARKS = np.sort(np.concatenate([LIPS_IDXS0, LEFT_HAND_IDXS0, RIGHT_HAND_IDXS0, LEFT_POSE_IDXS0, RIGHT_POSE_IDXS0]))\n# print(REDUCED_LANDMARKS)\n\n\n# Opening JSON file\nf = open('/kaggle/input/asl-signs/sign_to_prediction_index_map.json')\n\n# opening train file\ntrain_path = '/kaggle/input/asl-signs/train.csv'\ntrain = pd.read_csv(train_path)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:25:30.630944Z\",\"iopub.execute_input\":\"2024-07-11T11:25:30.631394Z\",\"iopub.status.idle\":\"2024-07-11T11:25:30.640266Z\",\"shell.execute_reply.started\":\"2024-07-11T11:25:30.631359Z\",\"shell.execute_reply\":\"2024-07-11T11:25:30.639038Z\"}}\n# returns JSON object as \n# a dictionary\nWORD2IDX = json.load(f)\nprint(len(WORD2IDX), WORD2IDX)\n\nWORD = list(WORD2IDX.keys())\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:25:30.642747Z\",\"iopub.execute_input\":\"2024-07-11T11:25:30.643382Z\",\"iopub.status.idle\":\"2024-07-11T11:25:30.666698Z\",\"shell.execute_reply.started\":\"2024-07-11T11:25:30.643343Z\",\"shell.execute_reply\":\"2024-07-11T11:25:30.665635Z\"}}\ntrain.head()\n\n# %% [markdown]\n# ## Useful functions\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:25:30.668153Z\",\"iopub.execute_input\":\"2024-07-11T11:25:30.668490Z\",\"iopub.status.idle\":\"2024-07-11T11:25:30.674582Z\",\"shell.execute_reply.started\":\"2024-07-11T11:25:30.668461Z\",\"shell.execute_reply\":\"2024-07-11T11:25:30.673411Z\"}}\nROWS_PER_FRAME = 543  # number of landmarks per frame\n\ndef load_relevant_data_subset(pq_path):\n    data_columns = ['x', 'y']\n    data = pd.read_parquet(pq_path, columns=data_columns)\n    n_frames = int(len(data) / ROWS_PER_FRAME)\n    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n    return data.astype(np.float32)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:25:30.675739Z\",\"iopub.execute_input\":\"2024-07-11T11:25:30.676112Z\",\"iopub.status.idle\":\"2024-07-11T11:25:30.689675Z\",\"shell.execute_reply.started\":\"2024-07-11T11:25:30.676075Z\",\"shell.execute_reply\":\"2024-07-11T11:25:30.688446Z\"}}\ndef select_random_sequence():\n    usr = random.choice(user_ids)\n    usr_sqc = os.listdir(os.path.join(dataset_path,usr))\n    sqc = random.choice(usr_sqc)\n    return os.path.join(dataset_path,usr,sqc)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:25:30.691199Z\",\"iopub.execute_input\":\"2024-07-11T11:25:30.692128Z\",\"iopub.status.idle\":\"2024-07-11T11:25:30.703529Z\",\"shell.execute_reply.started\":\"2024-07-11T11:25:30.692052Z\",\"shell.execute_reply\":\"2024-07-11T11:25:30.702147Z\"}}\ndef normalize_loaded_sequence(loaded_sqc):\n    '''\n        Function to normalize using min-max normalization. \n        Normalization is calculated over all points, but only relevants landmarks points are returned\n        This function also replaces NaN by 0\n    '''\n    normalized_sqc = np.zeros((loaded_sqc.shape[0], len(REDUCED_LANDMARKS), 2))\n    \n    for frm_idx in range(loaded_sqc.shape[0]):\n        frame_array = loaded_sqc[frm_idx]\n        \n        na_x = np.nan_to_num(frame_array[:,0], nan=0.0)\n        na_y = np.nan_to_num(frame_array[:,1], nan=0.0)\n\n\n        x_norm = (na_x-np.min(na_x))/(np.max(na_x)-np.min(na_x))\n        y_norm = (na_y-np.min(na_y))/(np.max(na_y)-np.min(na_y))\n\n        normalized_sqc[frm_idx,:,0],  normalized_sqc[frm_idx,:,1] = x_norm[REDUCED_LANDMARKS], y_norm[REDUCED_LANDMARKS]\n    \n    return normalized_sqc\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:25:30.705451Z\",\"iopub.execute_input\":\"2024-07-11T11:25:30.706187Z\",\"iopub.status.idle\":\"2024-07-11T11:25:30.713031Z\",\"shell.execute_reply.started\":\"2024-07-11T11:25:30.706145Z\",\"shell.execute_reply\":\"2024-07-11T11:25:30.711931Z\"}}\ndef get_data(sqc_path):\n    data = load_relevant_data_subset(sqc_path)\n    data = normalize_loaded_sequence(data)\n    return data\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:25:30.714498Z\",\"iopub.execute_input\":\"2024-07-11T11:25:30.714895Z\",\"iopub.status.idle\":\"2024-07-11T11:25:30.724908Z\",\"shell.execute_reply.started\":\"2024-07-11T11:25:30.714858Z\",\"shell.execute_reply\":\"2024-07-11T11:25:30.723595Z\"}}\ndef get_word_from_key(key_index):\n    position = list(WORD2IDX.values()).index(key_index)\n    return WORD[position]\n\n# %% [markdown]\n# ## Data analysis\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:25:30.729757Z\",\"iopub.execute_input\":\"2024-07-11T11:25:30.730157Z\",\"iopub.status.idle\":\"2024-07-11T11:25:33.244076Z\",\"shell.execute_reply.started\":\"2024-07-11T11:25:30.730121Z\",\"shell.execute_reply\":\"2024-07-11T11:25:33.242627Z\"}}\ncols = ['frame', 'row_id', 'type', 'landmark_index', 'x', 'y', 'z']\npq_path = select_random_sequence()\ndf = pd.read_parquet(pq_path, columns=cols)\nprint(pq_path)\nprint(f'xmax: {np.max(df.x)}\\nymax: {np.max(df.y)}\\nxmin: {np.min(df.x)}\\nymin: {np.min(df.y)}')\n\n# %% [markdown]\n# ### **Prepocessing**\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:25:33.246033Z\",\"iopub.execute_input\":\"2024-07-11T11:25:33.246501Z\",\"iopub.status.idle\":\"2024-07-11T11:25:33.257926Z\",\"shell.execute_reply.started\":\"2024-07-11T11:25:33.246460Z\",\"shell.execute_reply\":\"2024-07-11T11:25:33.256549Z\"}}\ndef normalize_sequence(sequence_dataframe):\n    '''\n        function to normalize coordinates columns (x,y) per frame, also replace NaN values by column mean\n        sequence_dataset is a pandas dataframe containing a sequence of an user\n    '''\n\n\n\n    frame_sqc_idx = sqc_df.frame.unique()\n    normalized_df = pd.DataFrame()\n\n    for frame in frame_sqc_idx:\n        frame_df = sqc_df[sqc_df.frame == frame]\n        frame_df1 = frame_df.copy()\n        \n        na_x = frame_df['x'].fillna(0.0)\n        na_y = frame_df['y'].fillna(0.0)\n\n        x_norm = (na_x-np.min(na_x))/(np.max(na_x)-np.min(na_x))\n        y_norm = (na_y-np.min(na_y))/(np.max(na_y)-np.min(na_y))\n\n        frame_df1.x, frame_df1.y = x_norm, y_norm\n        normalized_df = pd.concat([normalized_df, frame_df1])\n    \n    return normalized_df\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:25:33.259865Z\",\"iopub.execute_input\":\"2024-07-11T11:25:33.260955Z\",\"iopub.status.idle\":\"2024-07-11T11:25:34.343823Z\",\"shell.execute_reply.started\":\"2024-07-11T11:25:33.260911Z\",\"shell.execute_reply\":\"2024-07-11T11:25:34.342623Z\"}}\npq_path = select_random_sequence() # only first sequence of user here\ncols = ['frame', 'row_id', 'type', 'landmark_index', 'x', 'y', 'z']\nsqc_df = pd.read_parquet(pq_path, columns=cols)\n\nvv = get_data(pq_path)\n\nn_df = normalize_sequence(sqc_df)\nframe_df0 = n_df[n_df.frame == n_df.frame.unique()[0]]\nframe_df1 = n_df[n_df.frame == n_df.frame.unique()[-1]]\n\nX0 = frame_df0.x\nY0= frame_df0.y\n\nX1 = frame_df1.x\nY1= frame_df1.y\n\nplt.figure(figsize=(10,8))\nplt.subplot(1,2,1)\nplt.xlim(0,1)\nplt.scatter(X0,-Y0+1, s=5)\nplt.legend(['543 original landmarks'])\n\nplt.subplot(1,2,2)\n# plt.scatter(X1,-Y1)\n# plt.scatter(vv[-1,:,0],-vv[-1,:,1], s=3, c='r')\nplt.xlim(0,1)\nplt.ylim(0,1)\nplt.scatter(vv[0,:,0],-vv[0,:,1]+1, s=7, c='r')\nplt.legend(['92 relevant landmarks'])\n\n\n# plt.title(pq_path)\nplt.show()\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:25:34.345177Z\",\"iopub.execute_input\":\"2024-07-11T11:25:34.345500Z\",\"iopub.status.idle\":\"2024-07-11T11:25:34.360719Z\",\"shell.execute_reply.started\":\"2024-07-11T11:25:34.345472Z\",\"shell.execute_reply\":\"2024-07-11T11:25:34.359265Z\"}}\nd=train.sign.value_counts(dropna=True)\nprint(f'mean number of sequence per sign: {d.mean()}')\nprint(f\"standard deviation {d.std()}\")\nprint(f\"max number of sequence {d.max()}\")\nprint(f\"min number of sequence {d.min()}\")\n\n# word distribution is not too expended\n# any words have close occurences\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:25:34.362001Z\",\"iopub.execute_input\":\"2024-07-11T11:25:34.362376Z\",\"iopub.status.idle\":\"2024-07-11T11:25:34.380261Z\",\"shell.execute_reply.started\":\"2024-07-11T11:25:34.362342Z\",\"shell.execute_reply\":\"2024-07-11T11:25:34.379149Z\"}}\ntrain.head()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:25:34.381896Z\",\"iopub.execute_input\":\"2024-07-11T11:25:34.382409Z\",\"iopub.status.idle\":\"2024-07-11T11:25:34.396024Z\",\"shell.execute_reply.started\":\"2024-07-11T11:25:34.382379Z\",\"shell.execute_reply\":\"2024-07-11T11:25:34.394953Z\"}}\ndf = train[['participant_id', 'sequence_id']]\ndf.head()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:25:34.397424Z\",\"iopub.execute_input\":\"2024-07-11T11:25:34.397710Z\",\"iopub.status.idle\":\"2024-07-11T11:25:34.406504Z\",\"shell.execute_reply.started\":\"2024-07-11T11:25:34.397687Z\",\"shell.execute_reply\":\"2024-07-11T11:25:34.405441Z\"}}\ndf_group = df.groupby(['participant_id'])['sequence_id'].size()\ndf_result = df_group.reset_index(name=\"nbr_of_sequences\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:25:34.408252Z\",\"iopub.execute_input\":\"2024-07-11T11:25:34.408727Z\",\"iopub.status.idle\":\"2024-07-11T11:25:35.451012Z\",\"shell.execute_reply.started\":\"2024-07-11T11:25:34.408690Z\",\"shell.execute_reply\":\"2024-07-11T11:25:35.450027Z\"}}\nimport seaborn as sns\n\n# Create a bar plot using Seaborn\nplt.figure(figsize=(10, 6))\nsns.barplot(x=np.array([i for i in range(21)]), y='nbr_of_sequences', data=df_result, palette='viridis')\n\n# Add titles and labels\nplt.title('Number of Sequences per Participant')\nplt.xlabel('Participant ID')\nplt.ylabel('Number of Sequences')\n\n# Show the plot\nplt.show()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:25:35.452574Z\",\"iopub.execute_input\":\"2024-07-11T11:25:35.452974Z\",\"iopub.status.idle\":\"2024-07-11T11:25:35.470390Z\",\"shell.execute_reply.started\":\"2024-07-11T11:25:35.452940Z\",\"shell.execute_reply\":\"2024-07-11T11:25:35.469400Z\"}}\ndf2 = train[['sign', 'sequence_id']]\ndf2.head()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:25:35.471863Z\",\"iopub.execute_input\":\"2024-07-11T11:25:35.472348Z\",\"iopub.status.idle\":\"2024-07-11T11:25:35.488838Z\",\"shell.execute_reply.started\":\"2024-07-11T11:25:35.472310Z\",\"shell.execute_reply\":\"2024-07-11T11:25:35.487739Z\"}}\ndf_group = df2.groupby(['sign'])['sequence_id'].size()\ndf_result = df_group.reset_index(name=\"nbr_of_sequences\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:25:35.490214Z\",\"iopub.execute_input\":\"2024-07-11T11:25:35.490528Z\",\"iopub.status.idle\":\"2024-07-11T11:25:37.866746Z\",\"shell.execute_reply.started\":\"2024-07-11T11:25:35.490502Z\",\"shell.execute_reply\":\"2024-07-11T11:25:37.865465Z\"}}\n# Create a bar plot using Seaborn\nplt.figure(figsize=(30, 5))\nsns.barplot(x=np.array([i for i in range(250)]), y='nbr_of_sequences', data=df_result, palette='viridis')\n\n# Add titles and labels\nplt.title('Number of Sequences per Signs')\nplt.xlabel('signs')\nplt.ylabel('Number of Sequences')\n\n# Show the plot\nplt.show()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:25:37.867967Z\",\"iopub.execute_input\":\"2024-07-11T11:25:37.868471Z\",\"iopub.status.idle\":\"2024-07-11T11:25:37.883614Z\",\"shell.execute_reply.started\":\"2024-07-11T11:25:37.868439Z\",\"shell.execute_reply\":\"2024-07-11T11:25:37.882447Z\"}}\ndf2.sign.value_counts()\n\n# %% [markdown]\n# ## Pre process dataset \n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:25:37.885008Z\",\"iopub.execute_input\":\"2024-07-11T11:25:37.885382Z\",\"iopub.status.idle\":\"2024-07-11T11:25:37.893267Z\",\"shell.execute_reply.started\":\"2024-07-11T11:25:37.885353Z\",\"shell.execute_reply\":\"2024-07-11T11:25:37.892286Z\"}}\ndef preprocess_dataset(train):\n    processed_dataset = []\n    for idx,path in enumerate(train.path):\n        sequence_path = os.path.join(COMPETITION_PATH, path)\n        word = train[train.path == path].sign.values[0]\n        processed_sqc = get_data(sequence_path)\n\n        processed_dataset.append((processed_sqc, word))\n        \n    \n    return processed_dataset\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:25:37.894693Z\",\"iopub.execute_input\":\"2024-07-11T11:25:37.895007Z\",\"iopub.status.idle\":\"2024-07-11T11:25:37.902785Z\",\"shell.execute_reply.started\":\"2024-07-11T11:25:37.894980Z\",\"shell.execute_reply\":\"2024-07-11T11:25:37.901563Z\"}}\n# to save dataset\n# with open(\"preprocess_dataset.pkl\", \"wb\") as fp:   #Pickling\n#     pickle.dump(processed_dataset, fp)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:25:37.904140Z\",\"iopub.execute_input\":\"2024-07-11T11:25:37.905795Z\",\"iopub.status.idle\":\"2024-07-11T11:26:25.372442Z\",\"shell.execute_reply.started\":\"2024-07-11T11:25:37.905758Z\",\"shell.execute_reply\":\"2024-07-11T11:26:25.371274Z\"}}\n# to load dataset\nwith open(PROCESS_DATASET_PATH, \"rb\") as fp:   # Unpickling\n    dataset = pickle.load(fp)\n\n# %% [markdown]\n# ### **Custom class and Dataloader**\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:26:25.373907Z\",\"iopub.execute_input\":\"2024-07-11T11:26:25.374261Z\",\"iopub.status.idle\":\"2024-07-11T11:26:27.400815Z\",\"shell.execute_reply.started\":\"2024-07-11T11:26:25.374232Z\",\"shell.execute_reply\":\"2024-07-11T11:26:27.399623Z\"}}\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom sklearn.model_selection import train_test_split\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:26:27.402112Z\",\"iopub.execute_input\":\"2024-07-11T11:26:27.402612Z\",\"iopub.status.idle\":\"2024-07-11T11:26:27.411176Z\",\"shell.execute_reply.started\":\"2024-07-11T11:26:27.402583Z\",\"shell.execute_reply\":\"2024-07-11T11:26:27.409938Z\"}}\nclass ISLR(Dataset):\n    def __init__(self, dataset, split):\n        self.split = split\n        self.dataset = dataset\n        \n        if split == 'trainval':\n            self.islr_dataset = dataset[:int(0.8*len(dataset))]\n        elif split =='test':\n            self.islr_dataset = dataset[int(0.8*len(dataset)):]\n        \n    def __len__(self):\n        return len(self.islr_dataset)\n    \n    def __getitem__(self, index):\n        sample = self.islr_dataset[index]\n        features = torch.FloatTensor(sample[0])\n        target = WORD2IDX[sample[1]]\n        \n        return features, target\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:26:27.412491Z\",\"iopub.execute_input\":\"2024-07-11T11:26:27.412807Z\",\"iopub.status.idle\":\"2024-07-11T11:26:27.426598Z\",\"shell.execute_reply.started\":\"2024-07-11T11:26:27.412781Z\",\"shell.execute_reply\":\"2024-07-11T11:26:27.425512Z\"}}\ntestset = ISLR(dataset, split='test')\ntrainvalset = ISLR(dataset, split='trainval')\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:26:27.431843Z\",\"iopub.execute_input\":\"2024-07-11T11:26:27.432229Z\",\"iopub.status.idle\":\"2024-07-11T11:26:30.551823Z\",\"shell.execute_reply.started\":\"2024-07-11T11:26:27.432198Z\",\"shell.execute_reply\":\"2024-07-11T11:26:30.550870Z\"}}\ntrainset, valset = train_test_split(trainvalset,test_size=0.1, random_state=42)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:26:30.553176Z\",\"iopub.execute_input\":\"2024-07-11T11:26:30.553568Z\",\"iopub.status.idle\":\"2024-07-11T11:26:30.561233Z\",\"shell.execute_reply.started\":\"2024-07-11T11:26:30.553533Z\",\"shell.execute_reply\":\"2024-07-11T11:26:30.559996Z\"}}\ndef custom_collate_fn(batch):\n    padded_batch = []\n    labels= []\n\n    max_frame = max(len(sequence) for sequence,_ in batch)\n#     print(max_frame)\n    for sequence, label in batch:\n        padding_array = -np.ones(((max_frame-len(sequence)), len(REDUCED_LANDMARKS), 2))\n        padded_sequence = sequence.tolist()+padding_array.tolist()\n\n        padded_batch.append(padded_sequence)\n        labels.append(label)\n\n\n    return torch.tensor(padded_batch), torch.tensor(labels)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:26:30.562779Z\",\"iopub.execute_input\":\"2024-07-11T11:26:30.563596Z\",\"iopub.status.idle\":\"2024-07-11T11:26:30.573550Z\",\"shell.execute_reply.started\":\"2024-07-11T11:26:30.563555Z\",\"shell.execute_reply\":\"2024-07-11T11:26:30.572447Z\"}}\ntrain_loader = DataLoader(trainset, \n                          batch_size=8, \n                          collate_fn=custom_collate_fn, \n                          shuffle=True,\n                          num_workers=4)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:26:30.574876Z\",\"iopub.execute_input\":\"2024-07-11T11:26:30.575226Z\",\"iopub.status.idle\":\"2024-07-11T11:26:30.584604Z\",\"shell.execute_reply.started\":\"2024-07-11T11:26:30.575195Z\",\"shell.execute_reply\":\"2024-07-11T11:26:30.583477Z\"}}\nval_loader = DataLoader(valset,\n                        batch_size=8,\n                        collate_fn=custom_collate_fn,\n                        shuffle=False,\n                        num_workers=4)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:26:30.586305Z\",\"iopub.execute_input\":\"2024-07-11T11:26:30.586692Z\",\"iopub.status.idle\":\"2024-07-11T11:26:30.595506Z\",\"shell.execute_reply.started\":\"2024-07-11T11:26:30.586664Z\",\"shell.execute_reply\":\"2024-07-11T11:26:30.594417Z\"}}\ntest_loader = DataLoader(testset,\n                         batch_size=8,\n                         collate_fn=custom_collate_fn,\n                         shuffle=False,\n                         num_workers=4)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:26:30.596784Z\",\"iopub.execute_input\":\"2024-07-11T11:26:30.597216Z\",\"iopub.status.idle\":\"2024-07-11T11:26:30.973504Z\",\"shell.execute_reply.started\":\"2024-07-11T11:26:30.597171Z\",\"shell.execute_reply\":\"2024-07-11T11:26:30.970581Z\"}}\ncustom_it = enumerate(train_loader)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:26:30.978328Z\",\"iopub.execute_input\":\"2024-07-11T11:26:30.980553Z\",\"iopub.status.idle\":\"2024-07-11T11:26:31.630631Z\",\"shell.execute_reply.started\":\"2024-07-11T11:26:30.980459Z\",\"shell.execute_reply\":\"2024-07-11T11:26:31.629161Z\"}}\nidx,(sqc,lb)=next(custom_it)\n\n# %% [markdown]\n# ## **Model architecture**\n\n# %% [markdown]\n# ### Transformer\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:26:31.632407Z\",\"iopub.execute_input\":\"2024-07-11T11:26:31.633099Z\",\"iopub.status.idle\":\"2024-07-11T11:26:31.654281Z\",\"shell.execute_reply.started\":\"2024-07-11T11:26:31.633044Z\",\"shell.execute_reply\":\"2024-07-11T11:26:31.653043Z\"}}\nclass TransformerModel(nn.Module):\n    def __init__(self, input_dim, num_heads, num_layers, hidden_dim, output_dim, n_landmarks, max_seq_length=1000):\n        super(TransformerModel, self).__init__()\n        self.embedding = nn.Linear(input_dim*n_landmarks, hidden_dim) # change encoding \n        self.layer_norm1 = nn.LayerNorm(hidden_dim)\n        self.positional_encoding = self.create_positional_encoding(max_seq_length, hidden_dim)\n        encoder_layers = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads)\n        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n        \n        \n    def forward(self, x):\n        \n        batch_size, n_frames, n_landmarks, input_dim = x.shape\n        pad_mask = self.sequence_mask(x)\n        pad_mask = pad_mask.to(device)\n        \n        # Flatten n_landmarks and input_dim for embedding\n        x = x.view(batch_size, n_frames, -1)\n        x = x.to(device)\n        x = self.embedding(x)\n        \n        x = self.layer_norm1(x)\n        x += self.positional_encoding[:, :n_frames, :].to(device)\n        x = x.permute(1, 0, 2)  # Transformer expects sequence length first\n                \n        transformer_out = self.transformer_encoder(x,src_key_padding_mask=pad_mask)\n        out = self.fc(transformer_out[-1, :, :])\n        assert not torch.isnan(out).any(), \"NaN in final output\"\n        \n        return out\n    \n    def create_positional_encoding(self, max_seq_length, hidden_dim):\n        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, hidden_dim, 2).float() * (-torch.log(torch.tensor(10000.0)) / hidden_dim))\n        \n        positional_encoding = torch.zeros(max_seq_length, hidden_dim)\n        positional_encoding[:, 0::2] = torch.sin(position * div_term)\n        positional_encoding[:, 1::2] = torch.cos(position * div_term)\n        \n        return positional_encoding.unsqueeze(0)\n    \n    def sequence_mask(self, sequence):\n        lengths = [self.valid_len(padded_sequence) for padded_sequence in sequence]\n        \n        mask = torch.zeros(sequence.size()[:2], dtype=torch.bool)  # shape: [batch_size, n_frames]\n        for i, length in enumerate(lengths):\n            mask[i, :length] = 1\n        \n        mask = ~mask # True values are ignored\n        return mask\n\n        \n    def valid_len(self, padded_sequence):\n        for idx, frame in  enumerate(padded_sequence):\n            if -1 in frame:\n                break\n\n        return idx+1\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:26:31.655744Z\",\"iopub.execute_input\":\"2024-07-11T11:26:31.656494Z\",\"iopub.status.idle\":\"2024-07-11T11:26:31.785688Z\",\"shell.execute_reply.started\":\"2024-07-11T11:26:31.656453Z\",\"shell.execute_reply\":\"2024-07-11T11:26:31.784468Z\"}}\ninput_dim = 2  # (x, y)\nnum_heads = 4\nnum_layers = 2\nhidden_dim = 64\noutput_dim = 250  # number of classes\nn_landmarks = 92\n\n\nmodel1 = TransformerModel(input_dim=input_dim,\n                         num_heads=num_heads,\n                         num_layers=num_layers,\n                         hidden_dim=hidden_dim,\n                         output_dim=output_dim,\n                         n_landmarks=n_landmarks)\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel1 = model1.to(device)\nprint(model1)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:26:31.790824Z\",\"iopub.execute_input\":\"2024-07-11T11:26:31.793584Z\",\"iopub.status.idle\":\"2024-07-11T11:26:31.816616Z\",\"shell.execute_reply.started\":\"2024-07-11T11:26:31.793537Z\",\"shell.execute_reply\":\"2024-07-11T11:26:31.815536Z\"}}\n# smaller model, model2\n\nnum_heads = 2\nnum_layers = 1\nhidden_dim = 32\n\n\nmodel2 = TransformerModel(input_dim=input_dim,\n                         num_heads=num_heads,\n                         num_layers=num_layers,\n                         hidden_dim=hidden_dim,\n                         output_dim=output_dim,\n                         n_landmarks=n_landmarks)\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel2 = model2.to(device)\nprint(model2)\n\n# %% [markdown]\n# ## **Training Phase**\n\n# %% [markdown]\n# ### Train several models to compare\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:29:05.123738Z\",\"iopub.execute_input\":\"2024-07-11T11:29:05.124276Z\",\"iopub.status.idle\":\"2024-07-11T11:29:05.131034Z\",\"shell.execute_reply.started\":\"2024-07-11T11:29:05.124221Z\",\"shell.execute_reply\":\"2024-07-11T11:29:05.129763Z\"}}\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:29:07.023339Z\",\"iopub.execute_input\":\"2024-07-11T11:29:07.024335Z\",\"iopub.status.idle\":\"2024-07-11T11:29:07.028956Z\",\"shell.execute_reply.started\":\"2024-07-11T11:29:07.024298Z\",\"shell.execute_reply\":\"2024-07-11T11:29:07.027645Z\"}}\nMODEL1_PATH = \"/kaggle/input/islr_transformer_model1_30epochs/pytorch/model1_45ep/1/pointnet_transformer_model1_45.pth\"\nMODEL2_PATH = \"/kaggle/input/islr_transformer_model2/pytorch/model2_45ep/1/pointnet_transformer_model2_45.pth\"\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:29:07.655338Z\",\"iopub.execute_input\":\"2024-07-11T11:29:07.655736Z\",\"iopub.status.idle\":\"2024-07-11T11:29:07.730828Z\",\"shell.execute_reply.started\":\"2024-07-11T11:29:07.655705Z\",\"shell.execute_reply\":\"2024-07-11T11:29:07.729824Z\"}}\ninput_dim = 2  # (x, y)\nnum_heads = 4\nnum_layers = 2\nhidden_dim = 64\noutput_dim = 250\nn_landmarks = 92\n\nmodel1 = TransformerModel(input_dim=input_dim,\n                         num_heads=num_heads,\n                         num_layers=num_layers,\n                         hidden_dim=hidden_dim,\n                         output_dim=output_dim,\n                         n_landmarks=n_landmarks)\n\nif  torch.cuda.is_available():\n    model1.load_state_dict(torch.load(MODEL1_PATH))\nelse:\n    model1.load_state_dict(torch.load(MODEL1_PATH, map_location=torch.device('cpu')))\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:29:08.426973Z\",\"iopub.execute_input\":\"2024-07-11T11:29:08.427953Z\",\"iopub.status.idle\":\"2024-07-11T11:29:08.456464Z\",\"shell.execute_reply.started\":\"2024-07-11T11:29:08.427917Z\",\"shell.execute_reply\":\"2024-07-11T11:29:08.455427Z\"}}\ninput_dim = 2  # (x, y)\nnum_heads = 2\nnum_layers = 1\nhidden_dim = 32\noutput_dim = 250\nn_landmarks = 92\n\nmodel2 = TransformerModel(input_dim=input_dim,\n                         num_heads=num_heads,\n                         num_layers=num_layers,\n                         hidden_dim=hidden_dim,\n                         output_dim=output_dim,\n                         n_landmarks=n_landmarks)\n\nif torch.cuda.is_available():\n    model2.load_state_dict(torch.load(MODEL2_PATH))\nelse:\n    model2.load_state_dict(torch.load(MODEL2_PATH, map_location=torch.device('cpu')))\n\n# %% [code]\nmodel1.to(device)\nmodel2.to(device)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\no1 = model1(sqc)\no2 = model2(sqc)\n\n# %% [code]\nloss_function = nn.CrossEntropyLoss()\noptim1 = optim.SGD(model1.parameters(), lr=0.001, momentum=0.9)\noptim2 = optim.SGD(model2.parameters(), lr=0.001, momentum=0.9)\n\n# %% [code]\n# num_epochs = 15\n\n# dataloader = train_loader\n\n# for epoch in range(num_epochs):\n\n#     print(f'Epoch {epoch+1}/{num_epochs}')\n#     print('-' * 10)\n    \n#     model1.train()\n#     model2.train()\n    \n#     running_l1 = 0.0\n#     running_l2 = 0.0\n\n#     for sequence, label in dataloader:\n#         sequence, label = sequence.to(device), label.to(device)\n        \n#         optim1.zero_grad()\n#         optim2.zero_grad()\n\n\n#         target = label\n        \n#         out1 = model1(sequence)\n#         out2 = model2(sequence)\n\n\n#         # Compute the loss, gradients, and update optimizer\n#         loss1 = loss_function(out1, target)\n#         loss2 = loss_function(out2, target)\n\n#         loss1.backward()\n#         loss2.backward()\n        \n#         optim1.step()\n#         optim2.step()\n\n    \n#         running_l1 += loss1.item()\n#         running_l2 += loss2.item()\n        \n\n\n#     epoch_l1 = running_l1 / len(dataloader)\n#     epoch_l2 = running_l2 / len(dataloader)\n\n#     print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {epoch_l1:.4f}\")\n#     print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {epoch_l2:.4f}\")\n\n    \n#     # Validation step\n#     model1.eval()\n#     model2.eval()\n\n#     val_loss1 = 0.0\n#     correct_top5_mod1 = 0\n#     correct_mod1 = 0\n    \n#     val_loss2 = 0.0\n#     correct_top5_mod2 = 0\n#     correct_mod2= 0\n    \n#     total = 0\n    \n#     with torch.no_grad():\n#         for sequence, label in val_loader:\n#             sequence, label = sequence.to(device), label.to(device)\n            \n#             out1 = model1(sequence)\n#             out2 = model2(sequence)\n\n#             loss1 = loss_function(out1, label)\n#             loss2 = loss_function(out2, label)\n\n#             val_loss1 += loss1.item() * sequence.size(0)\n#             val_loss2 += loss2.item() * sequence.size(0)\n\n            \n# #           use top 5 pred\n#             _, pred1_top5 = torch.topk(out1, 5, dim=1)\n#             _, pred2_top5 = torch.topk(out2, 5, dim=1)\n\n#             correct_top5_mod1 += (pred1_top5.to(device) == label.view(-1, 1)).sum().item()\n#             correct_top5_mod2 += (pred2_top5.to(device) == label.view(-1, 1)).sum().item()\n\n# #             top prediction\n#             _, pred1 = torch.max(out1, 1)\n#             _, pred2 = torch.max(out2, 1)\n\n#             correct_mod1 += (pred1 == label).sum().item()\n#             correct_mod2 += (pred2 == label).sum().item()\n            \n            \n#             total += label.size(0)\n\n\n\n#     val_loss1 /= len(val_loader.dataset)\n#     val_loss2 /= len(val_loader.dataset)\n    \n#     val_acc1 = correct_mod1 /total\n#     val_acc2 = correct_mod2 /total\n\n#     val_acc1_top5 = correct_top5_mod1/total\n#     val_acc2_top5 = correct_top5_mod2/total\n\n#     print(f'(model1) val loss: {val_loss1:.4f} Acc: {val_acc1:.4f} Top 5 Acc: {val_acc1_top5:.4f}')\n#     print(f'(model2) val loss: {val_loss2:.4f} Acc: {val_acc2:.4f} Top 5 Acc: {val_acc2_top5:.4f}')\n\n\n#     torch.save(model1.state_dict(), f'pointnet_transformer_model1_{epoch+1}.pth')\n#     torch.save(model2.state_dict(), f'pointnet_transformer_model2_{epoch+1}.pth')\n\n# %% [markdown]\n# ### Load model and analyze\n\n# %% [code]\nMODEL_PATH = \"/kaggle/input/islr_transformer_model1_30epochs/pytorch/model1_60ep/1/pointnet_transformer_model1_60.pth\"\n\n# %% [code]\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\ninput_dim = 2  # (x, y)\nnum_heads = 4\nnum_layers = 2\nhidden_dim = 64\noutput_dim = 250\nn_landmarks = 92\n\nmodel_load = TransformerModel(input_dim=input_dim,\n                         num_heads=num_heads,\n                         num_layers=num_layers,\n                         hidden_dim=hidden_dim,\n                         output_dim=output_dim,\n                         n_landmarks=n_landmarks)\n\nif torch.cuda.is_available():\n    model_load.load_state_dict(torch.load(MODEL_PATH))\nelse:\n    model_load.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device('cpu')))\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\nmodel_load.to(device)\n\n# %% [code]\nfrom prettytable import PrettyTable\n\ndef count_parameters(model):\n    table = PrettyTable([\"Modules\", \"Parameters\"])\n    total_params = 0\n    for name, parameter in model.named_parameters():\n        if not parameter.requires_grad:\n            continue\n        params = parameter.numel()\n        table.add_row([name, params])\n        total_params += params\n    print(table)\n    print(f\"Total Trainable Params: {total_params}\")\n    return total_params\n    \ncount_parameters(model_load)\n\n# %% [code]\ncorrect = 0\ntotal = 0\nmodel_load.eval()\ntrue_labels = []\npredicted_labels = []\n\nconfusion_matrix = torch.zeros(250, 250)\n\nwith torch.no_grad():\n      for i, (sequence, label) in enumerate(test_loader):\n            sequence, label = sequence.to(device), label.to(device)\n            \n            outputs = model_load(sequence)\n\n            _, pred = torch.max(outputs, 1)\n            correct += (pred == label).sum().item()\n            \n            true_labels = true_labels+label.tolist()\n            predicted_labels = predicted_labels+pred.tolist()\n\n            total += label.size(0)\n            \n            for t, p in zip(label.view(-1), pred.view(-1)):\n                confusion_matrix[t.long(), p.long()] += 1\n\n#             if i%200==0:\n#                 print(f'Ground Truth: {label}')\n#                 print(f'Prediction: {pred}')\n#                 print('-'*10)\n\nprint(f'Accuracy of the network on the test set: {100 * correct // total} %')\n\n# %% [code]\nif \"cm_test.pt\" in os.listdir(\"/kaggle/input/confusion-matrix/\"):\n    confusion_matrix = torch.load(\"/kaggle/input/confusion-matrix/cm_test.pt\")\nelse:\n    torch.save(confusion_matrix, \"cm_test.pt\")\n\n# %% [code]\nimport pandas as pd\n\nif \"class_report.csv\" in os.listdir(\"/kaggle/input/class-report\"):\n    print('loading class_report.csv...')\n    class_report_df = pd.read_csv(\"/kaggle/input/class-report/class_report.csv\")\n    print('class_report loaded')\n    \nelse: \n    print('create classification report')\n    report = classification_report(true_labels, predicted_labels, output_dict=True)\n    # Convert the report dictionary to a pandas DataFrame\n    report_df = pd.DataFrame(report).transpose()\n    class_report_df = report_df.drop(['accuracy','macro avg', 'weighted avg'])\n    class_report_df.to_csv(\"/kaggle/working/class_report.csv\", header=True, index=False)\n    print('saved to /kaggle/working/class_report.csv')\n\n# %% [code]\nf1_score=class_report_df['f1-score']\nsupport = class_report_df['support']\n\n# %% [code]\nvalue_to_keep = 5\nsorted_classes=np.argsort(f1_score.values)\nworst_classes = sorted_classes[:value_to_keep]\nbest_classes = sorted_classes[-value_to_keep:]\n\n# %% [code]\nfor class_idx in worst_classes:\n    print(get_word_from_key(class_idx))\n\n# %% [code]\nfor class_idx in best_classes:\n    print(get_word_from_key(class_idx))\n\n# %% [code]\ndef mean_len_word_sqcs(class_index):\n    word = get_word_from_key(class_index)\n    worst_class_path = train[train.sign == word].path.values\n    sequence_length = []\n    for idx,sqc_path in enumerate(worst_class_path):\n        sequence = get_data(os.path.join(COMPETITION_PATH,sqc_path))\n        sequence_length.append(len(sequence))\n\n\n    return np.mean(sequence_length), np.std(sequence_length)\n\n# %% [code]\nfor class_idx in best_classes:\n    print(f'{get_word_from_key(class_idx)} : {mean_len_word_sqcs(class_idx)}')\n\n# %% [code]\nfor class_idx in worst_classes:\n    print(f'{get_word_from_key(class_idx)} : {mean_len_word_sqcs(class_idx)}')\n\n# %% [markdown]\n# ## **Results analysis**\n\n# %% [code]\nper_class_acc = confusion_matrix.diag()/confusion_matrix.sum(1)\n\n# %% [code]\nper_class_acc\n\n# %% [code]\nworst_acc, worst_classes = torch.topk(1-per_class_acc, k=5)\nworst_acc = 1-worst_acc\n\nworst_acc, worst_classes\n\n# %% [code]\nbest_acc, best_classes = torch.topk(per_class_acc, k=5)\n\nbest_acc,best_classes\n\n# %% [code]\nfor class_idx in (worst_classes):\n\n    number_of_pred, pred_classes = torch.topk(confusion_matrix[int(class_idx)], 2)\n    true_word = get_word_from_key(class_idx)\n    acc = np.round(float(per_class_acc[class_idx]),3)\n    total_preds = confusion_matrix[class_idx,:].sum().item()\n    print(f'true word: {true_word} (class accuracy: {acc})')\n    \n    for idx, pred in enumerate(pred_classes):\n        pred_word = get_word_from_key(pred)\n        word_acc = number_of_pred[idx]/total_preds\n        w_acc = np.round(word_acc, 2)\n        print(f'{100*w_acc}% <{pred_word}> predicted as <{true_word}>')\n        \n    print('------------------------')\n\n# %% [code]\nworst_sign = get_word_from_key(worst_classes[0])\nworst_class_path = train[train.sign == worst_sign].path.values\n\nbest_sign = get_word_from_key(best_classes[0])\nbest_class_path = train[train.sign == best_sign].path.values\n\n# %% [code]\npath1 = random.choice(worst_class_path)\nseq1 = get_data(os.path.join(COMPETITION_PATH,path1))\n\nprint(f'number of frames: {len(seq1)}')\n\nfig = plt.figure(figsize=(8,8))\n\nhfig = display(fig, display_id=True)\n\nT = 3\n\ndef update():\n    for i in range(len(seq1)):\n\n        plt.clf()\n        plt.xlim(0,100)\n        plt.ylim(-100,0)\n        plt.scatter(100*seq1[i,:,0],-100*seq1[i,:,1], s=5, c='r')\n        plt.title(f'{worst_sign}, frame {i+1}/{len(seq1)}')\n        hfig.update(fig)\n        print()\n        time.sleep(T/len(seq1))\n    \n\nupdate()\nplt.close(fig)\n\n# %% [code]\nclass_idx = worst_classes[0]\nnumber_of_pred, pred_classes = torch.topk(confusion_matrix[int(class_idx)], 2)\n\nsign1 = get_word_from_key(pred_classes[0])\nsign2 = get_word_from_key(pred_classes[1])\n\npath1 = random.choice(train[train.sign == sign1].path.values)\nseq1 = get_data(os.path.join(COMPETITION_PATH,path1))\nseq_len=-100\n\npath_it = iter(train[train.sign == sign2].path.values)\nwhile np.abs(seq_len-len(seq1))>5:\n    path2 = next(path_it)\n    seq2 = get_data(os.path.join(COMPETITION_PATH,path2))\n    seq_len=len(seq2)\n\n\nseq2 = get_data(os.path.join(COMPETITION_PATH,path2))\n\nprint(f'number of frames: {len(seq1)} and {len(seq2)}')\n\nfig = plt.figure(figsize=(10,8))\n\nhfig = display(fig, display_id=True)\n\nT = 3\nN = min(len(seq1),len(seq2))\n\ndef update():\n    for i in range(N):\n        plt.clf()\n        \n        plt.subplot(1,2,1)\n        plt.xlim(0,100)\n        plt.ylim(-100,0)\n        plt.scatter(100*seq1[i,:,0],-100*seq1[i,:,1], s=5, c='r')\n        plt.title(sign1)\n        \n        plt.subplot(1,2,2)\n        plt.xlim(0,100)\n        plt.ylim(-100,0)\n        plt.scatter(100*seq2[i,:,0],-100*seq2[i,:,1], s=5, c='r')\n        plt.title(sign2)\n        \n        hfig.update(fig)\n        time.sleep(T/N)\n    \n\nupdate()\nplt.close(fig)\n\n# %% [markdown]\n# ## **Data Augmentation**\n\n# %% [markdown]\n# Data Augmentation\n# \n# Spatial augmentation\n# \n# Gaussian Noise\n# Translation\n# Masking : random erasing\n# Mixup : Combine 2 images and their associated labels with a given ratio, can be done for example with a random body part\n# \n# Temporal Augmentation\n# \n# Time Shift : shift temporal sequence\n# To run before launching data augmentation (for information)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-07-11T11:38:12.519172Z\",\"iopub.execute_input\":\"2024-07-11T11:38:12.519587Z\",\"iopub.status.idle\":\"2024-07-11T11:38:12.557705Z\",\"shell.execute_reply.started\":\"2024-07-11T11:38:12.519557Z\",\"shell.execute_reply\":\"2024-07-11T11:38:12.556791Z\"}}\npath_per_user = {}\nfor user in user_ids:\n    # all file paths of one user\n    user_paths = list(train[train.participant_id == int(user)].path.values)\n    path_per_user[int(user)] = user_paths\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-07-11T12:23:36.448628Z\",\"iopub.execute_input\":\"2024-07-11T12:23:36.449326Z\",\"iopub.status.idle\":\"2024-07-11T12:23:36.457533Z\",\"shell.execute_reply.started\":\"2024-07-11T12:23:36.449284Z\",\"shell.execute_reply\":\"2024-07-11T12:23:36.456281Z\"}}\n# Count mean frame\nparticipants = path_per_user.keys()\nprint(participants)\nprint(len(participants))\nnb_values_cumul = 0\nfor keys,values in path_per_user.items() : \n    nb_values = len(values)\n    nb_values_cumul += nb_values\n    print('total number of values for keys', keys, \":\", nb_values)\nprint('mean number of frame: ', nb_values_cumul/len(participants))\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-07-11T12:20:06.875272Z\",\"iopub.execute_input\":\"2024-07-11T12:20:06.875683Z\",\"iopub.status.idle\":\"2024-07-11T12:20:08.267749Z\",\"shell.execute_reply.started\":\"2024-07-11T12:20:06.875650Z\",\"shell.execute_reply\":\"2024-07-11T12:20:08.266158Z\"}}\nmax_frame_list = []\nfor keys,file_paths in path_per_user.items() :\n    for file_path in file_paths:        \n        data = pd.read_parquet(os.path.join(COMPETITION_PATH,file_path), columns=['frame'])\n        max_frame_value = data['frame'].max()\n        max_frame_list.append(max_frame_value)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-07-11T12:21:36.432576Z\",\"iopub.execute_input\":\"2024-07-11T12:21:36.434083Z\",\"iopub.status.idle\":\"2024-07-11T12:21:36.834550Z\",\"shell.execute_reply.started\":\"2024-07-11T12:21:36.434011Z\",\"shell.execute_reply\":\"2024-07-11T12:21:36.833267Z\"}}\nimport matplotlib.pyplot as plt\nplt.hist(max_frame_list, bins = 40, color = 'skyblue', edgecolor='black')\nplt.xlabel('Maximum frame value')\nplt.ylabel('Frequency')\nplt.title('Distribution of maximum frame values')\nplt.grid(True)\nplt.show()\n\n# %% [code]\nmini = 30\nmaxi = 60\nnb_value_min_max = sum(1 for value in max_frame_list if mini <= value <= maxi)\nper_plage = (nb_value_min_max / len(max_frame_list)) * 100\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-06-27T08:48:09.036035Z\",\"iopub.execute_input\":\"2024-06-27T08:48:09.036620Z\",\"iopub.status.idle\":\"2024-06-27T08:48:09.049893Z\",\"shell.execute_reply.started\":\"2024-06-27T08:48:09.036581Z\",\"shell.execute_reply\":\"2024-06-27T08:48:09.048241Z\"}}\nclass ISLR(Dataset) : \n    def __init__(self, dataset,split):\n        self.split = split\n        self.dataset = dataset\n        \n        if split == 'trainval':\n            self.islr_dataset = dataset[:int(0.8*len(dataset))]\n        elif split == 'test':\n            self.islr_dataset = dataset[int(0.8*len(dataset)):]\n    \n    def __len__(self):\n        return len(self.islr_dataset)\n    \n    def __getitem__(self, index):\n        sample = self.islr_dataset[index]\n        features = torch.FloatTensor(sample[0])\n        target = WORD2IDX[sample[1]]\n        \n        return features, target\n    \n    def get_sequences_by_target(self, target_value):\n        sequences = []\n        for sample in self.islr_dataset:\n            features = torch.FloatTensor(sample[0])\n            target = WORD2IDX[sample[1]]\n            if target == target_value:\n                sequences.append((features, target))\n            if len(sequences) == 2:  # Stop after finding two sequences\n                break\n        return sequences\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-06-27T08:48:09.846923Z\",\"iopub.execute_input\":\"2024-06-27T08:48:09.847413Z\",\"iopub.status.idle\":\"2024-06-27T08:48:09.888930Z\",\"shell.execute_reply.started\":\"2024-06-27T08:48:09.847380Z\",\"shell.execute_reply\":\"2024-06-27T08:48:09.887299Z\"}}\nclass DataAugmentation:\n    def __init__(self, dataset, noise_std=0.01, translation_range=0.1, erasing_probability_range=(0.1, 0.5), erasing_value=(0, 0), max_shift=5):\n        self.noise_std = noise_std\n        self.translation_range = translation_range\n        self.erasing_probability_range = erasing_probability_range\n        self.erasing_value = erasing_value\n        self.max_shift = max_shift\n        self.dataset = dataset\n        \n        # Define body part indices\n        self.LIPS_IDXS0 = np.array([\n            61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n            291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n            78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n            95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n        ])\n        self.LEFT_HAND_IDXS0 = np.arange(468, 489)\n        self.RIGHT_HAND_IDXS0 = np.arange(522, 543)\n        self.LEFT_POSE_IDXS0 = np.array([502, 504, 506, 508, 510])\n        self.RIGHT_POSE_IDXS0 = np.array([503, 505, 507, 509, 511])\n\n        self.REDUCED_LANDMARKS = np.sort(np.concatenate([self.LIPS_IDXS0, self.LEFT_HAND_IDXS0, self.RIGHT_HAND_IDXS0, self.LEFT_POSE_IDXS0, self.RIGHT_POSE_IDXS0]))\n        self.index_map = {value: idx for idx, value in enumerate(self.REDUCED_LANDMARKS)}\n\n        self.lips_indices_in_reduced = [self.index_map[idx] for idx in self.LIPS_IDXS0]\n        self.left_hand_indices_in_reduced = [self.index_map[idx] for idx in self.LEFT_HAND_IDXS0]\n        self.right_hand_indices_in_reduced = [self.index_map[idx] for idx in self.RIGHT_HAND_IDXS0]\n        self.left_pose_indices_in_reduced = [self.index_map[idx] for idx in self.LEFT_POSE_IDXS0]\n        self.right_pose_indices_in_reduced = [self.index_map[idx] for idx in self.RIGHT_POSE_IDXS0]\n\n        self.BODY_PARTS = {\n            'lips': self.lips_indices_in_reduced,\n            'left_hand': self.left_hand_indices_in_reduced,\n            'right_hand': self.right_hand_indices_in_reduced,\n            'left_pose': self.left_pose_indices_in_reduced,\n            'right_pose': self.right_pose_indices_in_reduced\n        }\n\n    def add_gaussian_noise(self, features):\n        noise = torch.randn_like(features) * self.noise_std\n        noisy_features = features + noise\n        noisy_features = torch.clamp(noisy_features, 0, 1)  # Clamping to keep values within [0, 1]\n        return noisy_features\n\n    def translation(self, features):\n        tr_x = random.uniform(-self.translation_range, self.translation_range)\n        tr_y = random.uniform(-self.translation_range, self.translation_range)\n        translated_features = features.clone()  # Cloning to avoid modifying the original features\n        translated_features[:, 0] += tr_x\n        translated_features[:, 1] += tr_y\n        translated_features = torch.clamp(translated_features, 0, 1)  # Clamping to keep values within [0, 1]\n        return translated_features\n\n    def random_erasing(self, points):\n        probability = random.uniform(*self.erasing_probability_range)\n        if random.uniform(0, 1) > probability:\n            return points\n        points_copy = points.clone()\n        nb_points = len(points_copy)\n        nb_points_erased = int(nb_points * random.uniform(0.1, 0.5))\n        erased_indices = random.sample(range(nb_points), nb_points_erased)\n        for idx in erased_indices:\n            points_copy[idx] = torch.tensor(self.erasing_value, dtype=points_copy.dtype)\n        return points_copy\n\n    def time_shift_images(self, sequence):\n        shift = random.randint(-self.max_shift, self.max_shift)\n        seq_len, num_points, num_features = sequence.shape\n        shifted_sequence = torch.zeros_like(sequence)  \n        for i in range(seq_len):\n            if 0 <= i + shift < seq_len:\n                shifted_sequence[i + shift] = sequence[i]\n        return shifted_sequence\n\n    def mixup_body_part_sequence(self, sequence1, sequence2, part_indices):\n        # Obtenir les longueurs des squences\n        len1 = len(sequence1)\n        len2 = len(sequence2)\n        # Dterminer la longueur commune\n        min_len = min(len1, len2)\n        # Tronquer les squences  la longueur commune\n        sequence1 = sequence1[:min_len]\n        sequence2 = sequence2[:min_len]\n        # Cloner la seconde squence pour viter de la modifier directement\n        mixed_sequence = sequence2.clone()\n        # Appliquer le mixup pour chaque image dans la squence\n        for i in range(min_len):\n            mixed_sequence[i][part_indices] = sequence1[i][part_indices]\n        return mixed_sequence\n\n    def get_random_body_part(self):\n        body_part_name = random.choice(list(self.BODY_PARTS.keys()))\n        body_part_indices = self.BODY_PARTS[body_part_name]\n        return body_part_name, body_part_indices\n\n    def get_sequences_by_target(self, target_value):\n        sequences = [seq for seq in self.dataset if seq[1] == target_value]\n        return sequences\n\n    def scatter_plot(self, features, title='Scatter Plot', body_part_indices=None):\n        first_image = features[0]\n        x_coords = first_image[:, 0]\n        y_coords = first_image[:, 1]\n        plt.scatter(x_coords, -y_coords, label='Other Points', color='blue')\n        if body_part_indices:\n            plt.scatter(x_coords[body_part_indices], -y_coords[body_part_indices], label='Body Part', color='red')\n        plt.xlabel('X Axis')\n        plt.ylabel('Y Axis')\n        plt.title(title)\n        plt.legend()\n        plt.show()\n\n    def augment_dataset(self, proportion=0.1, output_file='augmented_data.pkl'):\n        num_samples = len(self.dataset)\n        num_to_augment = int(proportion * num_samples)\n        indices_to_augment = random.sample(range(num_samples), num_to_augment)\n        new_sequences = []\n        \n        for idx in indices_to_augment:\n            sequence, target = self.dataset[idx]\n            augmentation_choice = random.choice([\n                self.add_gaussian_noise,\n                self.translation,\n                self.random_erasing,\n                self.time_shift_images,\n                self.apply_mixup_to_random_body_part\n            ])\n            if augmentation_choice == self.apply_mixup_to_random_body_part:\n                other_sequence, _ = random.choice(self.get_sequences_by_target(target))\n                body_part_name, body_part_indices = self.get_random_body_part()\n                augmented_sequence = augmentation_choice(sequence, other_sequence, body_part_indices)\n            else:\n                augmented_sequence = augmentation_choice(sequence)\n            new_sequences.append((augmented_sequence, target))\n        # Save the augmented data to a file\n        with open(output_file, 'wb') as f:\n            pickle.dump(new_sequences, f)\n        print(f'Augmented data saved to {output_file}')\n        \n#         self.dataset.extend(new_sequences)  # Ajouter les nouvelles squences augmentes au dataset\n\n    def apply_mixup_to_random_body_part(self, sequence1, sequence2, part_indices):\n        return self.mixup_body_part_sequence(sequence1, sequence2, part_indices)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-06-27T08:48:12.738148Z\",\"iopub.execute_input\":\"2024-06-27T08:48:12.738675Z\",\"iopub.status.idle\":\"2024-06-27T08:48:24.693202Z\",\"shell.execute_reply.started\":\"2024-06-27T08:48:12.738637Z\",\"shell.execute_reply\":\"2024-06-27T08:48:24.691862Z\"}}\naugmentor = DataAugmentation(trainset)\n# Augment dataset by 10%\naugmentor.augment_dataset(proportion=0.1, output_file='augmented_data.pkl')\n\n# VDisplay a sequence\nsequence, target = random.choice(trainset)\naugmentor.scatter_plot(sequence, title='Scatter Plot of Augmented Sequence')","metadata":{"_uuid":"df8dbb60-8456-4fd3-a855-d6b74432c837","_cell_guid":"eb57a684-dfad-4a28-8787-1fca20e94138","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}