{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":46105,"databundleVersionId":5087314,"sourceType":"competition"},{"sourceId":8558594,"sourceType":"datasetVersion","datasetId":5115292,"isSourceIdPinned":false}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **Sign Language Recognition**","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport pickle\n\nimport os\nimport random\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:43:47.300103Z","iopub.execute_input":"2024-06-05T10:43:47.301215Z","iopub.status.idle":"2024-06-05T10:43:47.306167Z","shell.execute_reply.started":"2024-06-05T10:43:47.301176Z","shell.execute_reply":"2024-06-05T10:43:47.304698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COMPETITION_PATH = '/kaggle/input/asl-signs/'\nPROCESS_DATASET_PATH = \"/kaggle/input/preprocess-dataset/preprocess_dataset.pkl\"\ndataset_path = '/kaggle/input/asl-signs/train_landmark_files'\nuser_ids = os.listdir('/kaggle/input/asl-signs/train_landmark_files')","metadata":{"_uuid":"8a2ed463-0271-4ff3-a5be-9df7c58ba211","_cell_guid":"c03b8f78-be30-403e-abf9-dc08f4a8093b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-05T10:43:48.585108Z","iopub.execute_input":"2024-06-05T10:43:48.585476Z","iopub.status.idle":"2024-06-05T10:43:48.597238Z","shell.execute_reply.started":"2024-06-05T10:43:48.585449Z","shell.execute_reply":"2024-06-05T10:43:48.596111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Function to load sequence provided by Google","metadata":{}},{"cell_type":"code","source":"ROWS_PER_FRAME = 543  # number of landmarks per frame\n\ndef load_relevant_data_subset(pq_path):\n    data_columns = ['x', 'y']\n    data = pd.read_parquet(pq_path, columns=data_columns)\n    n_frames = int(len(data) / ROWS_PER_FRAME)\n    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n    return data.astype(np.float32)","metadata":{"_uuid":"4b4aeb99-68a2-4a24-9e3b-67b5c0039998","_cell_guid":"35525b8f-3e2b-4cb4-936c-cfc0a83ad7f1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-05T10:43:53.372576Z","iopub.execute_input":"2024-06-05T10:43:53.372967Z","iopub.status.idle":"2024-06-05T10:43:53.379145Z","shell.execute_reply.started":"2024-06-05T10:43:53.372936Z","shell.execute_reply":"2024-06-05T10:43:53.377949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def select_random_sequence():\n    usr = random.choice(user_ids)\n    usr_sqc = os.listdir(os.path.join(dataset_path,usr))\n    sqc = random.choice(usr_sqc)\n    return os.path.join(dataset_path,usr,sqc)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:43:53.994557Z","iopub.execute_input":"2024-06-05T10:43:53.994956Z","iopub.status.idle":"2024-06-05T10:43:54.001011Z","shell.execute_reply.started":"2024-06-05T10:43:53.994926Z","shell.execute_reply":"2024-06-05T10:43:53.999679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"select_random_sequence()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:43:54.642554Z","iopub.execute_input":"2024-06-05T10:43:54.642930Z","iopub.status.idle":"2024-06-05T10:43:55.136472Z","shell.execute_reply.started":"2024-06-05T10:43:54.642904Z","shell.execute_reply":"2024-06-05T10:43:55.135209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = ['frame', 'row_id', 'type', 'landmark_index', 'x', 'y', 'z']\npq_path = select_random_sequence()\ndf = pd.read_parquet(pq_path, columns=cols)\nprint(pq_path)\nprint(f'xmax: {np.max(df.x)}\\nymax: {np.max(df.y)}\\nxmin: {np.min(df.x)}\\nymin: {np.min(df.y)}')","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:43:55.284390Z","iopub.execute_input":"2024-06-05T10:43:55.284798Z","iopub.status.idle":"2024-06-05T10:43:56.084318Z","shell.execute_reply.started":"2024-06-05T10:43:55.284766Z","shell.execute_reply":"2024-06-05T10:43:56.083010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Do not run next cell (takes time)**\nor maybe run it one time for min values","metadata":{}},{"cell_type":"code","source":"# maxX=[]\n# maxY=[]\n# maxZ=[]\n# for usr in user_ids:\n#     usr_sqc = os.listdir(os.path.join(dataset_path,usr))\n#     for sqc in usr_sqc:\n#         pth = os.path.join(dataset_path,usr,sqc)\n#         df = pd.read_parquet(pth, columns=['x', 'y', 'z'])\n#         maxX.append(np.max(df.x))\n#         maxY.append(np.max(df.y))\n#         maxZ.append(np.max(df.z))\n\n# print(f'max x: {np.max(maxX)}\\nmax y: {np.max(maxY)}\\nmax z: {np.max(maxZ)}')\n\n'''\noutputs:\n\nmax x: 2.9205052852630615\nmax y: 3.572496175765991\nmax z: 4.796591758728027\n'''","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:43:58.836753Z","iopub.execute_input":"2024-06-05T10:43:58.837161Z","iopub.status.idle":"2024-06-05T10:43:58.845285Z","shell.execute_reply.started":"2024-06-05T10:43:58.837130Z","shell.execute_reply":"2024-06-05T10:43:58.843940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Prepocessing**","metadata":{"_uuid":"96455624-55ff-496a-ae6a-b43a25d42e49","_cell_guid":"515e9ae8-e27b-45b9-9cbf-498e13c15adf","trusted":true}},{"cell_type":"code","source":"# lips idx\nLIPS_IDXS0 = np.array([\n        61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n        291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n        78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n        95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n    ])\n\n# left hand, by taking account face from 0 to 468\nLEFT_HAND_IDXS0 = np.arange(468,489)\nRIGHT_HAND_IDXS0 = np.arange(522,543)\nLEFT_POSE_IDXS0 = np.array([502, 504, 506, 508, 510])\nRIGHT_POSE_IDXS0 = np.array([503, 505, 507, 509, 511])\n\nREDUCED_LANDMARKS = np.sort(np.concatenate([LIPS_IDXS0, LEFT_HAND_IDXS0, RIGHT_HAND_IDXS0, LEFT_POSE_IDXS0, RIGHT_POSE_IDXS0]))\nprint(REDUCED_LANDMARKS)","metadata":{"_uuid":"d7e9ea0d-eb40-47fd-bd15-6fc37dc189bd","_cell_guid":"eb35c44a-e422-4a26-aaed-1634b9b0a187","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-05T10:44:00.331774Z","iopub.execute_input":"2024-06-05T10:44:00.332278Z","iopub.status.idle":"2024-06-05T10:44:00.342545Z","shell.execute_reply.started":"2024-06-05T10:44:00.332241Z","shell.execute_reply":"2024-06-05T10:44:00.341342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Note** positions kept as wanted","metadata":{"_uuid":"cb76c0a9-7681-4d04-ae92-b7075ae924f0","_cell_guid":"d1209dc6-1b3f-4f8f-8e73-65aa5deb6286","trusted":true}},{"cell_type":"code","source":"# function to replace NaN and normalize columns \npq_path = select_random_sequence() # only first sequence of user here\ncols = ['frame', 'row_id', 'type', 'landmark_index', 'x', 'y', 'z']\nsqc_df = pd.read_parquet(pq_path, columns=cols)","metadata":{"_uuid":"70fd716b-b3af-464f-ba8d-d94c986cd84d","_cell_guid":"630a0c5b-3513-4b6c-9938-db7a40e671d1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-05T10:44:01.731342Z","iopub.execute_input":"2024-06-05T10:44:01.731727Z","iopub.status.idle":"2024-06-05T10:44:02.280711Z","shell.execute_reply.started":"2024-06-05T10:44:01.731699Z","shell.execute_reply":"2024-06-05T10:44:02.279323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalize_sequence(sequence_dataframe):\n    '''\n        function to normalize coordinates columns (x,y) per frame, also replace NaN values by column mean\n        sequence_dataset is a pandas dataframe containing a sequence of an user\n    '''\n\n\n\n    frame_sqc_idx = sqc_df.frame.unique()\n    normalized_df = pd.DataFrame()\n\n    for frame in frame_sqc_idx:\n        frame_df = sqc_df[sqc_df.frame == frame]\n        frame_df1 = frame_df.copy()\n        \n        na_x = frame_df['x'].fillna(0.0)\n        na_y = frame_df['y'].fillna(0.0)\n\n        x_norm = (na_x-np.min(na_x))/(np.max(na_x)-np.min(na_x))\n        y_norm = (na_y-np.min(na_y))/(np.max(na_y)-np.min(na_y))\n\n        frame_df1.x, frame_df1.y = x_norm, y_norm\n        normalized_df = pd.concat([normalized_df, frame_df1])\n    \n    return normalized_df\n\nnormalized_df=normalize_sequence(sqc_df)","metadata":{"_uuid":"266676e1-9f64-4089-89f9-3132d8a4d459","_cell_guid":"e6a44c03-95a4-4089-a7b9-e5c76f98a75b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-05T10:44:02.316742Z","iopub.execute_input":"2024-06-05T10:44:02.317894Z","iopub.status.idle":"2024-06-05T10:44:02.401664Z","shell.execute_reply.started":"2024-06-05T10:44:02.317847Z","shell.execute_reply":"2024-06-05T10:44:02.400656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(sqc_df), len(normalized_df)","metadata":{"_uuid":"43c86e09-c36a-42cd-9f3e-539c2727f4f6","_cell_guid":"169decec-b172-45df-8e72-2a78e1a1ac54","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-05T10:44:03.806858Z","iopub.execute_input":"2024-06-05T10:44:03.807250Z","iopub.status.idle":"2024-06-05T10:44:03.816376Z","shell.execute_reply.started":"2024-06-05T10:44:03.807219Z","shell.execute_reply":"2024-06-05T10:44:03.815094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"v = load_relevant_data_subset(select_random_sequence())\nprint(v.shape)","metadata":{"_uuid":"c3db2a48-c2e5-4bfe-8563-5e03f3f418a2","_cell_guid":"1e46e7f3-9137-4cde-b730-63a945d0f5bf","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-05T10:44:04.373501Z","iopub.execute_input":"2024-06-05T10:44:04.373892Z","iopub.status.idle":"2024-06-05T10:44:05.135957Z","shell.execute_reply.started":"2024-06-05T10:44:04.373862Z","shell.execute_reply":"2024-06-05T10:44:05.134769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalize_loaded_sequence(loaded_sqc):\n    '''\n        Function to normalize using min-max normalization. \n        Normalization is calculated over all points, but only relevants landmarks points are returned\n        This function also replaces NaN by 0\n    '''\n    normalized_sqc = np.zeros((loaded_sqc.shape[0], len(REDUCED_LANDMARKS), 2))\n    \n    for frm_idx in range(loaded_sqc.shape[0]):\n        frame_array = loaded_sqc[frm_idx]\n        \n        na_x = np.nan_to_num(frame_array[:,0], nan=0.0)\n        na_y = np.nan_to_num(frame_array[:,1], nan=0.0)\n\n\n        x_norm = (na_x-np.min(na_x))/(np.max(na_x)-np.min(na_x))\n        y_norm = (na_y-np.min(na_y))/(np.max(na_y)-np.min(na_y))\n\n        normalized_sqc[frm_idx,:,0],  normalized_sqc[frm_idx,:,1] = x_norm[REDUCED_LANDMARKS], y_norm[REDUCED_LANDMARKS]\n    \n    return normalized_sqc\n\nn_v = normalize_loaded_sequence(v)\nprint(n_v.shape)\nprint(np.max(n_v[0,:,0]), np.min(n_v[0,:,0]))","metadata":{"_uuid":"643848a0-4ccf-46a7-99ab-cda929f592e5","_cell_guid":"2dab81d5-16ff-48d2-8790-9f36ac83590f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-05T10:44:05.138250Z","iopub.execute_input":"2024-06-05T10:44:05.138616Z","iopub.status.idle":"2024-06-05T10:44:05.150317Z","shell.execute_reply.started":"2024-06-05T10:44:05.138572Z","shell.execute_reply":"2024-06-05T10:44:05.149099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Note** at this step I have a normalized tensor built after loading data","metadata":{"_uuid":"5eda37f5-532c-4a36-99df-b916504c5000","_cell_guid":"b60fa52b-9e47-4bc5-8d1e-61dbc5e6ae4d","trusted":true}},{"cell_type":"code","source":"def get_data(sqc_path):\n    data = load_relevant_data_subset(sqc_path)\n    data = normalize_loaded_sequence(data)\n    return data","metadata":{"_uuid":"d4436b6a-bc75-4d02-9cab-1ac038515a90","_cell_guid":"68fdc1a4-21f1-40fa-87f7-7075a606873b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-05T10:44:05.983438Z","iopub.execute_input":"2024-06-05T10:44:05.983846Z","iopub.status.idle":"2024-06-05T10:44:05.989656Z","shell.execute_reply.started":"2024-06-05T10:44:05.983812Z","shell.execute_reply":"2024-06-05T10:44:05.988307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d = get_data(select_random_sequence())\nd.shape\n# print(vv.shape)","metadata":{"_uuid":"371c1236-86e7-4a9c-95a9-02bc63e49c78","_cell_guid":"4ca93780-d865-4a62-9511-a9ce32c5347c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-05T10:44:06.447559Z","iopub.execute_input":"2024-06-05T10:44:06.448394Z","iopub.status.idle":"2024-06-05T10:44:07.051291Z","shell.execute_reply.started":"2024-06-05T10:44:06.448354Z","shell.execute_reply":"2024-06-05T10:44:07.050309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pq_path = select_random_sequence() # only first sequence of user here\ncols = ['frame', 'row_id', 'type', 'landmark_index', 'x', 'y', 'z']\nsqc_df = pd.read_parquet(pq_path, columns=cols)\n\nvv = get_data(pq_path)\n\nn_df = normalize_sequence(sqc_df)\nframe_df0 = n_df[n_df.frame == n_df.frame.unique()[0]]\nframe_df1 = n_df[n_df.frame == n_df.frame.unique()[-1]]\n\nX0 = frame_df0.x\nY0= frame_df0.y\n\nX1 = frame_df1.x\nY1= frame_df1.y\n\nplt.figure(figsize=(8,10))\nplt.subplot(1,2,1)\nplt.scatter(X0,-Y0)\nplt.scatter(vv[0,:,0],-vv[0,:,1], s=3, c='r')\n\nplt.subplot(1,2,2)\nplt.scatter(X1,-Y1)\nplt.scatter(vv[-1,:,0],-vv[-1,:,1], s=3, c='r')\n\nplt.title(pq_path)\nplt.show()","metadata":{"_uuid":"f1fd3fd8-4169-422d-bbf0-15d011449588","_cell_guid":"456db75e-3435-4cf0-b896-5a3bb34c4f27","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-05T10:44:08.681038Z","iopub.execute_input":"2024-06-05T10:44:08.681428Z","iopub.status.idle":"2024-06-05T10:44:09.766515Z","shell.execute_reply.started":"2024-06-05T10:44:08.681396Z","shell.execute_reply":"2024-06-05T10:44:09.765291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Note** \nNormalization using min-max change position of point when using less (but most important) landmarks, is it normal as we used less points.\nBut movement keep the same\n\n- RNN or LSTM can be a good simple approach for starting (it can be adapted for Time Series)","metadata":{"_uuid":"49a0c7d5-d80d-4fff-8fc2-8c790008d2e8","_cell_guid":"86e90895-409a-48c9-a476-f95fa5bb90f6","trusted":true}},{"cell_type":"markdown","source":"#### **TODO**\n* thing about data augmentation\n* try to use coatnet -> need to input data with same shape\n* padding ?\n    - issue with padding is that we have sequence with much more frames than other, maybe reduce thoses sequences and padding for small sequences\n    - goal: have se","metadata":{"_uuid":"7675f4a3-90ac-466f-81aa-71dc8a013be9","_cell_guid":"51503dec-8965-4f16-92cf-d368247a8591","trusted":true}},{"cell_type":"code","source":"train_path = '/kaggle/input/asl-signs/train.csv'\ntrain = pd.read_csv(train_path)\ntrain.head()","metadata":{"_uuid":"0dfd68e0-75d0-4bbe-afd7-6b78536a7d8d","_cell_guid":"f882640a-d50d-42bf-a16d-fc12bdbb8eca","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-05T10:44:12.466284Z","iopub.execute_input":"2024-06-05T10:44:12.466713Z","iopub.status.idle":"2024-06-05T10:44:12.742245Z","shell.execute_reply.started":"2024-06-05T10:44:12.466680Z","shell.execute_reply":"2024-06-05T10:44:12.740966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train)","metadata":{"_uuid":"96a82d03-43a0-4f0e-8614-03afffb8255f","_cell_guid":"f01ba453-73db-4675-81b1-e32104297a35","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-05T10:44:14.272783Z","iopub.execute_input":"2024-06-05T10:44:14.274196Z","iopub.status.idle":"2024-06-05T10:44:14.282030Z","shell.execute_reply.started":"2024-06-05T10:44:14.274154Z","shell.execute_reply":"2024-06-05T10:44:14.280682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"_uuid":"a87da9e2-191b-49c3-bd45-cad61cfe274e","_cell_guid":"99ca41cf-fbd9-4da9-bc94-cb21663a4739","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-05T10:44:14.661114Z","iopub.execute_input":"2024-06-05T10:44:14.661482Z","iopub.status.idle":"2024-06-05T10:44:14.668318Z","shell.execute_reply.started":"2024-06-05T10:44:14.661451Z","shell.execute_reply":"2024-06-05T10:44:14.667266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.sign.unique()","metadata":{"_uuid":"b75b0ae0-a132-48cf-9e7e-106d84d0ad95","_cell_guid":"bc3b4808-e2b6-4c66-8339-ca3f1fe0c203","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-05T10:44:15.012442Z","iopub.execute_input":"2024-06-05T10:44:15.012840Z","iopub.status.idle":"2024-06-05T10:44:15.030424Z","shell.execute_reply.started":"2024-06-05T10:44:15.012809Z","shell.execute_reply":"2024-06-05T10:44:15.029038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.participant_id.unique(), len(train.participant_id.unique())","metadata":{"_uuid":"91d8e63b-7c8d-4f77-b3b9-68834dc1c56b","_cell_guid":"0b8bbf47-e543-47fa-9516-26ce96925659","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-05T10:44:15.707129Z","iopub.execute_input":"2024-06-05T10:44:15.707504Z","iopub.status.idle":"2024-06-05T10:44:15.716378Z","shell.execute_reply.started":"2024-06-05T10:44:15.707474Z","shell.execute_reply":"2024-06-05T10:44:15.715226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d=dict(train.sign.value_counts(dropna=True))\nprint(train.sign.value_counts(dropna=True).mean())\nprint(train.sign.value_counts(dropna=True).std())\nprint(train.sign.value_counts(dropna=True).max())\nprint(train.sign.value_counts(dropna=True).min())\n\n# word distribution is not too expended\n# any words have close occurences","metadata":{"_uuid":"a4984607-fe7d-46ff-b22e-3f6912516e14","_cell_guid":"56cad90a-f855-4692-9fa7-f0488c39ad75","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-05T10:44:17.051300Z","iopub.execute_input":"2024-06-05T10:44:17.051690Z","iopub.status.idle":"2024-06-05T10:44:17.091264Z","shell.execute_reply.started":"2024-06-05T10:44:17.051658Z","shell.execute_reply":"2024-06-05T10:44:17.090057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Some notes:**\n* each parquet contains markers position [x y z] and type (face, left_hand, pose, right_hand) for different frame\n* train dataset is composed of image path, participant id (folder name of parquet file) sequence id (filename) and word said\n* one sequence = numerous frames = 1 word\n* every frame has data for each type, but it is possible that one type has no value in a frame, it is setted to NaN\n\n**Goal**: using hand position, be able to understand word said in the sequence\n* classification between 250 words using positions of body parts in video","metadata":{"_uuid":"1ca89a71-d415-447f-86b7-7fd59fd1ebcb","_cell_guid":"22413d80-e9ab-4be9-a253-cbe3afe4be65","trusted":true}},{"cell_type":"code","source":"import json\n \n# Opening JSON file\nf = open('/kaggle/input/asl-signs/sign_to_prediction_index_map.json')\n \n# returns JSON object as \n# a dictionary\nWORD2IDX = json.load(f)\nprint(len(WORD2IDX), WORD2IDX)","metadata":{"_uuid":"ba451a81-8561-48af-8824-e7c43884df61","_cell_guid":"1cd8ee38-bac7-4900-854f-740c01ec1ec3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-05T10:44:18.105149Z","iopub.execute_input":"2024-06-05T10:44:18.105946Z","iopub.status.idle":"2024-06-05T10:44:18.118502Z","shell.execute_reply.started":"2024-06-05T10:44:18.105911Z","shell.execute_reply":"2024-06-05T10:44:18.117257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_words = train.sign.unique()\nprint(len(train_words))\n# same length as sign to prediction index json","metadata":{"_uuid":"7db67ed7-f3dd-439b-8bf5-d982f32b7fa1","_cell_guid":"66437a49-e9c2-4e17-a794-19fefb6f51e9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-05T10:44:20.329288Z","iopub.execute_input":"2024-06-05T10:44:20.329686Z","iopub.status.idle":"2024-06-05T10:44:20.342352Z","shell.execute_reply.started":"2024-06-05T10:44:20.329652Z","shell.execute_reply":"2024-06-05T10:44:20.341110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_word = random.choice(train.sign.unique())\nprint(f'idx for <{random_word}> is <{WORD2IDX[random_word]}>')","metadata":{"_uuid":"c0f32063-c67d-45d0-a2fd-271aaa680481","_cell_guid":"a41fd89e-7462-4a86-bd13-34be0a7862e9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-05T10:44:20.995567Z","iopub.execute_input":"2024-06-05T10:44:20.995977Z","iopub.status.idle":"2024-06-05T10:44:21.008107Z","shell.execute_reply.started":"2024-06-05T10:44:20.995947Z","shell.execute_reply":"2024-06-05T10:44:21.006855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.path","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:44:21.602375Z","iopub.execute_input":"2024-06-05T10:44:21.602774Z","iopub.status.idle":"2024-06-05T10:44:21.611685Z","shell.execute_reply.started":"2024-06-05T10:44:21.602738Z","shell.execute_reply":"2024-06-05T10:44:21.610633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Custom Dataset class","metadata":{}},{"cell_type":"code","source":"all_sqc_path = train.path\nprint(len(all_sqc_path))","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:44:24.130568Z","iopub.execute_input":"2024-06-05T10:44:24.130952Z","iopub.status.idle":"2024-06-05T10:44:24.136955Z","shell.execute_reply.started":"2024-06-05T10:44:24.130923Z","shell.execute_reply":"2024-06-05T10:44:24.135667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"myList = []\n\nfor i in range(5):\n    sq1 = select_random_sequence()\n    word = train[train.path == sq1[24:]].sign.values[0]\n    mydata = get_data(sq1)\n    print(mydata.shape)\n    myList.append((mydata, word))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:44:24.506726Z","iopub.execute_input":"2024-06-05T10:44:24.507114Z","iopub.status.idle":"2024-06-05T10:44:26.586588Z","shell.execute_reply.started":"2024-06-05T10:44:24.507085Z","shell.execute_reply":"2024-06-05T10:44:26.585479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Don't run following cell, it creates *preprocess_dataset***","metadata":{}},{"cell_type":"code","source":"# Do not run !\n\n# processed_dataset = []\n# for idx,path in enumerate(train.path):\n#     sequence_path = os.path.join(COMPETITION_PATH, path)\n#     word = train[train.path == path].sign.values[0]\n#     processed_sqc = get_data(sequence_path)\n    \n#     processed_dataset.append((processed_sqc, word))\n    \n#     if idx%200 == 0:\n#         print(processed_sqc.shape, word)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:44:30.061968Z","iopub.execute_input":"2024-06-05T10:44:30.062379Z","iopub.status.idle":"2024-06-05T10:44:30.067318Z","shell.execute_reply.started":"2024-06-05T10:44:30.062348Z","shell.execute_reply":"2024-06-05T10:44:30.066067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to save dataset\n# with open(\"preprocess_dataset.pkl\", \"wb\") as fp:   #Pickling\n#     pickle.dump(processed_dataset, fp)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:44:30.622836Z","iopub.execute_input":"2024-06-05T10:44:30.623520Z","iopub.status.idle":"2024-06-05T10:44:30.627981Z","shell.execute_reply.started":"2024-06-05T10:44:30.623487Z","shell.execute_reply":"2024-06-05T10:44:30.626687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to load dataset\nwith open(PROCESS_DATASET_PATH, \"rb\") as fp:   # Unpickling\n    dataset = pickle.load(fp)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:44:32.174589Z","iopub.execute_input":"2024-06-05T10:44:32.174983Z","iopub.status.idle":"2024-06-05T10:45:34.529589Z","shell.execute_reply.started":"2024-06-05T10:44:32.174953Z","shell.execute_reply":"2024-06-05T10:45:34.528517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[0][1]","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:47:29.058659Z","iopub.execute_input":"2024-06-05T10:47:29.059772Z","iopub.status.idle":"2024-06-05T10:47:29.065916Z","shell.execute_reply.started":"2024-06-05T10:47:29.059730Z","shell.execute_reply":"2024-06-05T10:47:29.064902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:47:29.458826Z","iopub.execute_input":"2024-06-05T10:47:29.459341Z","iopub.status.idle":"2024-06-05T10:47:29.466949Z","shell.execute_reply.started":"2024-06-05T10:47:29.459300Z","shell.execute_reply":"2024-06-05T10:47:29.465623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Custom class and Dataloader**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:47:30.435169Z","iopub.execute_input":"2024-06-05T10:47:30.435567Z","iopub.status.idle":"2024-06-05T10:47:33.551577Z","shell.execute_reply.started":"2024-06-05T10:47:30.435535Z","shell.execute_reply":"2024-06-05T10:47:33.550433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ISLR(Dataset):\n    def __init__(self, dataset, split):\n        self.split = split\n        self.dataset = dataset\n        \n        if split == 'train':\n            self.islr_dataset = dataset[:int(0.8*len(dataset))]\n        elif split =='test':\n            self.islr_dataset = dataset[int(0.8*len(dataset)):]\n        \n    def __len__(self):\n        return len(self.islr_dataset)\n    \n    def __getitem__(self, index):\n        sample = self.islr_dataset[index]\n        features = torch.FloatTensor(sample[0])\n        target = WORD2IDX[sample[1]]\n        \n        return features, target\n    ","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:47:33.553539Z","iopub.execute_input":"2024-06-05T10:47:33.554089Z","iopub.status.idle":"2024-06-05T10:47:33.561321Z","shell.execute_reply.started":"2024-06-05T10:47:33.554058Z","shell.execute_reply":"2024-06-05T10:47:33.560111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testset = ISLR(dataset, split='test')\ntrainset = ISLR(dataset, split='train')","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:47:33.563109Z","iopub.execute_input":"2024-06-05T10:47:33.563529Z","iopub.status.idle":"2024-06-05T10:47:33.579039Z","shell.execute_reply.started":"2024-06-05T10:47:33.563492Z","shell.execute_reply":"2024-06-05T10:47:33.577913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:47:37.704707Z","iopub.execute_input":"2024-06-05T10:47:37.705661Z","iopub.status.idle":"2024-06-05T10:47:37.712262Z","shell.execute_reply.started":"2024-06-05T10:47:37.705624Z","shell.execute_reply":"2024-06-05T10:47:37.711121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(testset)+len(trainset)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:47:38.113022Z","iopub.execute_input":"2024-06-05T10:47:38.113402Z","iopub.status.idle":"2024-06-05T10:47:38.120379Z","shell.execute_reply.started":"2024-06-05T10:47:38.113373Z","shell.execute_reply":"2024-06-05T10:47:38.119209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# batch =[[torch.tensor([1833, 3205,  467,  342, 4165,   31, 49,  803]), torch.tensor([1])],\n#         [torch.tensor([1833, 3205,  467,  342, 49,  803]), torch.tensor([2])],\n#         [torch.tensor([1833, 3205,  467,  342, 4165,   31, 49,  803,52,54]), torch.tensor([1])]]\n# def custom_collate(batch):\n#     padded_batch=[]\n#     labels=[]\n#     for sentence,label in batch:\n#         # print(sentence.tolist())\n\n#         listSentence = sentence.tolist()\n#         max_len = max(len(sentence.tolist()) for sentence,label in batch)\n#         # print(listSentence)\n#         padded_sentence=listSentence+[5001]*(max_len-len(listSentence))\n#         # print(max_len)\n#         padded_batch.append(padded_sentence)\n#         labels.append(label)\n\n#     return torch.tensor(padded_batch), torch.tensor(labels)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:47:39.892430Z","iopub.execute_input":"2024-06-05T10:47:39.892841Z","iopub.status.idle":"2024-06-05T10:47:39.898417Z","shell.execute_reply.started":"2024-06-05T10:47:39.892809Z","shell.execute_reply":"2024-06-05T10:47:39.897067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef custom_collate_fn(batch):\n    padded_batch = []\n    labels= []\n\n    max_frame = max(len(sequence) for sequence,_ in batch)\n#     print(max_frame)\n    for sequence, label in batch:\n        padding_array = -np.ones(((max_frame-len(sequence)), len(REDUCED_LANDMARKS), 2))\n        padded_sequence = sequence.tolist()+padding_array.tolist()\n\n        padded_batch.append(padded_sequence)\n        labels.append(label)\n\n\n    return torch.tensor(padded_batch), torch.tensor(labels)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:47:40.215104Z","iopub.execute_input":"2024-06-05T10:47:40.215491Z","iopub.status.idle":"2024-06-05T10:47:40.223020Z","shell.execute_reply.started":"2024-06-05T10:47:40.215462Z","shell.execute_reply":"2024-06-05T10:47:40.221674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(trainset, batch_size=16, collate_fn=custom_collate_fn, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:47:42.178482Z","iopub.execute_input":"2024-06-05T10:47:42.179463Z","iopub.status.idle":"2024-06-05T10:47:42.184812Z","shell.execute_reply.started":"2024-06-05T10:47:42.179425Z","shell.execute_reply":"2024-06-05T10:47:42.183512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_it = enumerate(train_loader)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:47:44.341411Z","iopub.execute_input":"2024-06-05T10:47:44.341832Z","iopub.status.idle":"2024-06-05T10:47:44.378227Z","shell.execute_reply.started":"2024-06-05T10:47:44.341797Z","shell.execute_reply":"2024-06-05T10:47:44.376993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx,(sqc,lb)=next(custom_it)\nprint(sqc.shape, lb)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:47:45.439496Z","iopub.execute_input":"2024-06-05T10:47:45.440509Z","iopub.status.idle":"2024-06-05T10:47:46.190459Z","shell.execute_reply.started":"2024-06-05T10:47:45.440471Z","shell.execute_reply":"2024-06-05T10:47:46.189333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Model architecture**","metadata":{}},{"cell_type":"code","source":"# class SignLanguageModel(nn.Module):\n#     def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n#         super(SignLanguageModel, self).__init__()\n#         self.num_layers = num_layers\n#         self.hidden_dim = hidden_dim\n#         self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n#         self.fc = nn.Linear(hidden_dim, output_dim)\n\n#     def forward(self, x):\n#         h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n#         c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n#         out, _ = self.lstm(x, (h0, c0))\n#         out = self.fc(out[:, -1, :])\n#         return out\n","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:47:49.742803Z","iopub.execute_input":"2024-06-05T10:47:49.743190Z","iopub.status.idle":"2024-06-05T10:47:49.748166Z","shell.execute_reply.started":"2024-06-05T10:47:49.743161Z","shell.execute_reply":"2024-06-05T10:47:49.747023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TransformerModel(nn.Module):\n    def __init__(self, input_dim, num_heads, num_layers, hidden_dim, output_dim, n_landmarks):\n        super(TransformerModel, self).__init__()\n        self.embedding = nn.Linear(input_dim*n_landmarks, hidden_dim)\n        encoder_layers = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads)\n        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        \n        batch_size, n_frames, n_landmarks, input_dim = x.shape\n        pad_mask = self.sequence_mask(x)\n        pad_mask = pad_mask.to(device)\n        \n        \n        # Flatten n_landmarks and input_dim for embedding\n        x = x.view(batch_size, n_frames, -1)\n        assert not torch.isnan(x).any(), \"NaN in input embedding\"\n        \n        \n        x = self.embedding(x)\n        assert not torch.isnan(x).any(), \"NaN  after embedding\"\n        \n        \n        x = x.permute(1, 0, 2)  # Transformer expects sequence length first\n        \n        assert not torch.isnan(x).any(), \"NaN in input to TransformerEncoder\"\n        assert not torch.isnan(pad_mask).any(), \"NaN in mask\"\n        \n        for param in self.transformer_encoder.parameters():\n            assert not torch.isnan(param).any(), \"NaN in TransformerEncoderLayer parameters\"\n                \n        \n        transformer_out = self.transformer_encoder(x,src_key_padding_mask=pad_mask)\n        assert not torch.isnan(transformer_out).any(), \"NaN in transformer out\"\n        \n        \n        out = self.fc(transformer_out[-1, :, :])\n        assert not torch.isnan(out).any(), \"NaN in final output\"\n        \n        \n        return out\n    \n    def sequence_mask(self, sequence):\n        lengths = [self.valid_len(padded_sequence) for padded_sequence in sequence]\n        \n        mask = torch.zeros(sequence.size()[:2], dtype=torch.bool)  # shape: [batch_size, n_frames]\n        for i, length in enumerate(lengths):\n            mask[i, :length] = 1\n        \n        mask = ~mask # True values are ignored\n        return mask\n\n        \n    def valid_len(self, padded_sequence):\n        for idx, frame in  enumerate(padded_sequence):\n            if -1 in frame:\n                break\n\n        return idx+1","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:47:50.117480Z","iopub.execute_input":"2024-06-05T10:47:50.118215Z","iopub.status.idle":"2024-06-05T10:47:50.131408Z","shell.execute_reply.started":"2024-06-05T10:47:50.118176Z","shell.execute_reply":"2024-06-05T10:47:50.130021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exemple d'utilisation\ninput_dim = 2  # (x, y)\nnum_heads = 4\nnum_layers = 2\nhidden_dim = 64\noutput_dim = 250  # nombre de mots\nn_landmarks = 92\n\nmodel = TransformerModel(input_dim=input_dim,\n                         num_heads=num_heads,\n                         num_layers=num_layers,\n                         hidden_dim=hidden_dim,\n                         output_dim=output_dim,\n                         n_landmarks=n_landmarks)\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = model.to(device)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:48:24.126579Z","iopub.execute_input":"2024-06-05T10:48:24.127012Z","iopub.status.idle":"2024-06-05T10:48:24.147694Z","shell.execute_reply.started":"2024-06-05T10:48:24.126980Z","shell.execute_reply":"2024-06-05T10:48:24.146116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"v = model(sqc)\n[torch.argmax(vi, ) for vi in v]","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:48:26.311018Z","iopub.execute_input":"2024-06-05T10:48:26.311406Z","iopub.status.idle":"2024-06-05T10:48:26.612210Z","shell.execute_reply.started":"2024-06-05T10:48:26.311376Z","shell.execute_reply":"2024-06-05T10:48:26.611080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k_pred, idx = torch.topk(v, 3, dim=1)\nidx","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:48:33.090242Z","iopub.execute_input":"2024-06-05T10:48:33.090686Z","iopub.status.idle":"2024-06-05T10:48:33.104119Z","shell.execute_reply.started":"2024-06-05T10:48:33.090645Z","shell.execute_reply":"2024-06-05T10:48:33.102841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid_len(padded_sequence):\n    for idx, frame in  enumerate(padded_sequence):\n        if -1 in frame:\n            break\n    \n    return idx+1","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:48:42.988869Z","iopub.execute_input":"2024-06-05T10:48:42.989280Z","iopub.status.idle":"2024-06-05T10:48:42.996540Z","shell.execute_reply.started":"2024-06-05T10:48:42.989251Z","shell.execute_reply":"2024-06-05T10:48:42.995089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sqc.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:48:44.898901Z","iopub.execute_input":"2024-06-05T10:48:44.899274Z","iopub.status.idle":"2024-06-05T10:48:44.906002Z","shell.execute_reply.started":"2024-06-05T10:48:44.899247Z","shell.execute_reply":"2024-06-05T10:48:44.904639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lengths = [valid_len(padded_sequence) for padded_sequence in sqc]\nlengths","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:48:59.763219Z","iopub.execute_input":"2024-06-05T10:48:59.763618Z","iopub.status.idle":"2024-06-05T10:48:59.784328Z","shell.execute_reply.started":"2024-06-05T10:48:59.763571Z","shell.execute_reply":"2024-06-05T10:48:59.783075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask = torch.zeros(sqc.size()[:2], dtype=torch.bool)  # shape: [batch_size, n_frames, 1]\nprint(mask.shape)\nfor i, length in enumerate(lengths):\n    mask[i, :length] = 1","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:49:00.997061Z","iopub.execute_input":"2024-06-05T10:49:00.997456Z","iopub.status.idle":"2024-06-05T10:49:01.006394Z","shell.execute_reply.started":"2024-06-05T10:49:00.997425Z","shell.execute_reply":"2024-06-05T10:49:01.004775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask[1]","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:49:04.658486Z","iopub.execute_input":"2024-06-05T10:49:04.658919Z","iopub.status.idle":"2024-06-05T10:49:04.667989Z","shell.execute_reply.started":"2024-06-05T10:49:04.658885Z","shell.execute_reply":"2024-06-05T10:49:04.666815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mask = mask.sum(dim=1) == 0\nmask = ~mask\nmask[1]","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:49:07.190488Z","iopub.execute_input":"2024-06-05T10:49:07.191511Z","iopub.status.idle":"2024-06-05T10:49:07.200716Z","shell.execute_reply.started":"2024-06-05T10:49:07.191468Z","shell.execute_reply":"2024-06-05T10:49:07.199486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:49:09.768696Z","iopub.execute_input":"2024-06-05T10:49:09.769108Z","iopub.status.idle":"2024-06-05T10:49:09.776260Z","shell.execute_reply.started":"2024-06-05T10:49:09.769078Z","shell.execute_reply":"2024-06-05T10:49:09.775086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Training Phase**","metadata":{}},{"cell_type":"code","source":"loss_function = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:49:15.978399Z","iopub.execute_input":"2024-06-05T10:49:15.978828Z","iopub.status.idle":"2024-06-05T10:49:17.566358Z","shell.execute_reply.started":"2024-06-05T10:49:15.978797Z","shell.execute_reply":"2024-06-05T10:49:17.565133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# num_epochs = 15\n\n# dataloader = train_loader\n\n# for epoch in range(num_epochs):\n\n#     print(f'Epoch {epoch}/{num_epochs - 1}')\n#     print('-' * 10)\n    \n#     model.train()\n#     running_loss = 0.0\n#     running_corrects = 0\n\n#     for sequence, label in dataloader:\n#         sequence, label = sequence.to(device), label.to(device)\n#         optimizer.zero_grad()\n\n#         target = label\n        \n#         outputs = model(sequence)\n\n#         predictions = torch.argmax(outputs, dim=1) # get index of max word\n\n#         # Compute the loss, gradients, and update optimizer\n#         loss = loss_function(outputs, target)\n#         loss.backward()\n#         optimizer.step()\n        \n#         running_loss += loss.item()\n#         running_corrects += torch.sum(predictions == label)\n\n#     exp_lr_scheduler.step()\n\n#     epoch_loss = running_loss / len(dataloader)\n#     epoch_acc = running_corrects.double() /len(dataloader)\n\n#     print(f'Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:50:22.939269Z","iopub.execute_input":"2024-06-05T10:50:22.939866Z","iopub.status.idle":"2024-06-05T10:50:22.945242Z","shell.execute_reply.started":"2024-06-05T10:50:22.939830Z","shell.execute_reply":"2024-06-05T10:50:22.944002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Analysis Ideas**\n\n* class embalencement (count words for each element in train dataset)\n* size analysis (lenght of sequence, linked to words ?)\n* position ranges (x y z)\n* number of sequence per participant \n* train dataset will be splitted for train test val","metadata":{"_uuid":"8d759ac7-3270-414a-86e2-af7feca4f043","_cell_guid":"7858f8f4-9bb1-4edf-90b8-b3de71ed3036","trusted":true}}]}